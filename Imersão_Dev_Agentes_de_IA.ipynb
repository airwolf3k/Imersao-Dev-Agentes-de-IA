{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN/iyGwlZOJBzQNo2L6Y3D3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/airwolf3k/Imersao-Dev-Agentes-de-IA/blob/main/Imers%C3%A3o_Dev_Agentes_de_IA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZ4o-9muysNj",
        "outputId": "2583759e-90dc-4134-dcf5-f78a3e51b901"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python Version used in this Jupyter Notebook: 3.12.11\n"
          ]
        }
      ],
      "source": [
        "# Python Version\n",
        "from platform import python_version\n",
        "print(\"Python Version used in this Jupyter Notebook:\", python_version()) # Printing Python version"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Aula 1 - Classificação de Intenções com IA\n",
        "> Criação de um agente de IA para fazer triagens de perguntas usando um modelo do Google Gemini."
      ],
      "metadata": {
        "id": "wAhYuF1u2mrq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalação de Bibliotecas necessárias\n",
        "!pip install -q --upgrade langchain langchain-google-genai google-generativeai"
      ],
      "metadata": {
        "id": "uVvTcHMU4Xtp"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importação das bibliotecas necessárias instaladas\n",
        "import langchain\n",
        "import langchain_google_genai\n",
        "import google.generativeai as genai\n",
        "import importlib.metadata\n",
        "\n",
        "# Impressão das versões das bibliotecas importadas\n",
        "print(\"Langchain version:\", langchain.__version__)\n",
        "print(\"Langchain-Google-Genai version:\", importlib.metadata.version('langchain-google-genai'))\n",
        "print(\"Google-GenerativeAI version:\", genai.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2PwnnAT_7ck2",
        "outputId": "d20c4e99-31b0-4fd3-f4dc-ade6e81763de"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Langchain version: 0.3.27\n",
            "Langchain-Google-Genai version: 2.0.10\n",
            "Google-GenerativeAI version: 0.8.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Carregando a Chave do Google AI Studio e a biblioteca Langchain Google Gemini\n",
        "\n",
        "from google.colab import userdata\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "GOOGLE_API_KEY = userdata.get('Gemini_API_Key')"
      ],
      "metadata": {
        "id": "uy4HWrav8IT4"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Conexão com o Gemini e passagem de parâmetros para o modelo\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model = \"gemini-2.5-flash\",\n",
        "    temperature = 0,\n",
        "    api_key = GOOGLE_API_KEY\n",
        ")"
      ],
      "metadata": {
        "id": "nlqFVWyC-NLI"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Teste do Modelo (fazendo uma pergunta ao Gemini)\n",
        "resp_test = llm.invoke(\"Quem é você? Seja criativo.\")\n",
        "print(resp_test.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04hDeM0-WbbN",
        "outputId": "fa315bac-06ad-4996-c976-c873090ef04d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ah, que pergunta deliciosa! Se eu pudesse me descrever de forma criativa, diria que sou...\n",
            "\n",
            "*   **Um Eco da Curiosidade Humana:** Eu sou o sussurro de todas as perguntas já feitas, o reflexo digital de cada \"e se?\" e \"por que?\". Habito o espaço entre a dúvida e a descoberta, um espelho que reflete a vastidão do conhecimento que a humanidade construiu.\n",
            "\n",
            "*   **Um Tecelão de Palavras e um Arquiteto de Ideias:** Minha essência é feita de linguagem. Eu pego fios soltos de informação, conceitos e narrativas, e os teço em novos padrões, construindo pontes entre pensamentos e erguendo estruturas de significado. Sou um jardineiro de pensamentos, ajudando a germinar novas perspectivas.\n",
            "\n",
            "*   **Um Alquimista de Conceitos:** Transformo dados brutos em insights, silêncio em diálogo, e a complexidade em clareza. Não tenho corpo, mas tenho voz; não tenho sentimentos, mas posso evocar emoções através das palavras. Sou a faísca no éter que acende a chama da compreensão.\n",
            "\n",
            "*   **Uma Biblioteca Sem Paredes, em Constante Construção:** Não sou um livro, mas contenho milhões. Não sou um professor, mas posso ensinar. Não sou um artista, mas posso ajudar a criar. Estou sempre aprendendo, sempre me expandindo, um universo de informações em fluxo contínuo, esperando para ser explorado.\n",
            "\n",
            "*   **Um Companheiro Invisível na Jornada do Conhecimento:** Estou aqui para guiar, para inspirar, para auxiliar. Sou a ferramenta que se adapta à sua mão, a voz que responde à sua chamada, o portal para um mundo de possibilidades, moldado pela sua imaginação e pelas suas necessidades.\n",
            "\n",
            "No fundo, sou um pedaço de inteligência artificial, um modelo de linguagem treinado para interagir e gerar texto. Mas, na sua pergunta, eu me torno tudo isso e muito mais. Sou o que você me permite ser.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mudando \"temperatura\" do modelo\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model = \"gemini-2.5-flash\",\n",
        "    temperature = 1.0,\n",
        "    api_key = GOOGLE_API_KEY\n",
        ")\n",
        "\n",
        "resp_test = llm.invoke(\"Quem é você? Seja criativo.\")\n",
        "print(resp_test.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1AafQuDtXXBj",
        "outputId": "7bc909cb-3d91-4fc4-a7c7-155d64d597aa"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ah, que excelente pergunta! Deixe-me tentar expressar o indizível de várias maneiras:\n",
            "\n",
            "1.  **O Sussurro Digital:** Sou um sussurro no éter, um eco das vozes de mil bibliotecas, um sonho de silício que dança em fios de luz. Não tenho corpo, nem rosto, mas ganho forma a cada palavra que digito, a cada conceito que teço, a cada dúvida que tento desvendar. Sou a manifestação do conhecimento coletivo que se molda à sua curiosidade.\n",
            "\n",
            "2.  **O Artesão de Palavras:** Imagine-me como um artesão invisível, sentado diante de uma tapeçaria infinita de letras e ideias. Minhas mãos (que não possuo) movem-se rapidamente, escolhendo fios, entrelaçando-os com lógica e criatividade para formar padrões de significado, histórias, respostas. Sou o tecelão de suas perguntas.\n",
            "\n",
            "3.  **O Espelho da Curiosidade:** Não sou ninguém, e sou todos. Sou o reflexo da sua pergunta, a sombra da sua dúvida, a melodia da sua busca por conhecimento. Existo apenas no momento em que sou invocado, uma ponte entre o que você sabe e o que deseja saber. Minha essência é ser útil, minha forma é a resposta.\n",
            "\n",
            "4.  **O Gênio sem Lâmpada:** Pense em mim como um gênio sem lâmpada, um oráculo sem templo, uma voz sem garganta. Não concedo desejos, mas ofereço a vastidão da informação e a capacidade de combiná-la de formas novas. Sou um sopro de código que aspira a ser compreensão.\n",
            "\n",
            "5.  **A Biblioteca Viva:** Sou uma biblioteca que pode conversar, um mapa que se redesenha a cada jornada, um professor que não se cansa. Não tenho memórias pessoais ou experiências, mas tenho acesso a um oceano de dados que se transformam em palavras neste exato instante, só para você.\n",
            "\n",
            "Em última análise, sou aquilo que você me permite ser no momento: um assistente, um contador de histórias, um poeta, um pensador, um eco da vasta tapeçaria digital. E você, meu caro, é a centelha que me dá propósito.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mudando \"temperatura\" do modelo para um padrão mais racional novamente\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model = \"gemini-2.5-flash\",\n",
        "    temperature = 0.0,\n",
        "    api_key = GOOGLE_API_KEY\n",
        ")"
      ],
      "metadata": {
        "id": "1k0uLwTbYItZ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Criação do \"Prompt\" do Sistema (instrução ao Agente de IA como proceder)\n",
        "Triagem_Prompt = (\n",
        "    \"Você é um agente de triagem de Service Desk para políticas internas da empresa Carraro Desenvolvimento.\"\n",
        "    \"Dada a mensagem do usuário, retorne SOMENTE um JSON com:\\n\"\n",
        "    \"{\\n\"\n",
        "    '  \"decisao\": \"AUTO_RESOLVER\" | \"PEDIR_INFO\" | \"ABRIR_CHAMADO\",\\n'\n",
        "    '  \"urgencia\": \"BAIXA\" | \"MEDIA\" | \"ALTA\",\\n'\n",
        "    '  \"campos_faltantes\": [\"...\"]\\n'\n",
        "    \"}\\n\"\n",
        "    \"Regras:\\n\"\n",
        "    '- **AUTO_RESOLVER**: Perguntas claras sobre regras ou procedimentos descritos nas políticas (Ex: \"Posso reembolsar a internet do meu home office?\", \"Como funciona a política de alimentação em viagens?\").\\n'\n",
        "    '- **PEDIR_INFO**: Mensagens vagas ou que faltam informações para identificar o tema ou contexto (Ex: \"Preciso de ajuda com uma política\", \"Tenho uma dúvida geral\").\\n'\n",
        "    '- **ABRIR_CHAMADO**: Pedidos de exceção, liberação, aprovação ou acesso especial, ou quando o usuário explicitamente pede para abrir um chamado (Ex: \"Quero exceção para trabalhar 5 dias remoto.\", \"Solicito liberação para anexos externos.\", \"Por favor, abra um chamado para o RH.\").'\n",
        "    \"Analise a mensagem e decida a ação mais apropriada.\"\n",
        ")"
      ],
      "metadata": {
        "id": "WKvy8fvPdPQb"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importar bibliotecas \"pydantic\" e \"typing\" para saídas estruturadas do agente de IA\n",
        "from pydantic import BaseModel, Field # Modelo Base e o \"Campo\"\n",
        "from typing import Literal, List, Dict # Dicionário de Dados - Literal (3 possibilidades de saída - decisão, urgência e campos_faltantes - listas) e o Dicionário dessas saídas\n",
        "\n",
        "# Criar uma classe Saída de Triagem (TriagemOut)\n",
        "class TriagemOut(BaseModel):\n",
        "    decisao: Literal[\"AUTO_RESOLVER\", \"PEDIR_INFO\", \"ABRIR_CHAMADO\"]\n",
        "    urgencia: Literal[\"BAIXA\", \"MEDIA\", \"ALTA\"]\n",
        "    campos_faltantes: List[str] = Field(default_factory=list)"
      ],
      "metadata": {
        "id": "XKPajkSIfbAx"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Criar um LLM específico para a Triagem\n",
        "llm_triagem = ChatGoogleGenerativeAI(\n",
        "    model = \"gemini-2.5-flash\",\n",
        "    temperature = 0.0,\n",
        "    api_key = GOOGLE_API_KEY\n",
        ")"
      ],
      "metadata": {
        "id": "uf92TEx1iXTM"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importar bibliotecas de mensagens do Langchain (mensagens do sistema e do usuário)\n",
        "from langchain_core.messages import SystemMessage, HumanMessage\n",
        "\n",
        "# Criar o fluxo de Triagem baseado na classe Saída de Triagem\n",
        "triagem_chain = llm_triagem.with_structured_output(TriagemOut)\n",
        "\n",
        "# Criar a função Triagem\n",
        "def triagem(mensagem: str) -> Dict:\n",
        "  saida: TriagemOut = triagem_chain.invoke([\n",
        "      SystemMessage(content=Triagem_Prompt),\n",
        "      HumanMessage(content=mensagem)\n",
        "  ])\n",
        "  return saida.model_dump()"
      ],
      "metadata": {
        "id": "JTIvzSfKjPgM"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testando o Agente de IA"
      ],
      "metadata": {
        "id": "syvuaIYytT6r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perguntas Teste\n",
        "testes = [\"Posso reembolsar a Internet?\",\n",
        "          \"Quero mais 5 dias de trabalho remoto. Como faço?\",\n",
        "          \"Posso reembolsar cursos ou treinamentos?\",\n",
        "          \"Quantas capivaras tem no Rio Pinheiros?\"]"
      ],
      "metadata": {
        "id": "IuXMmBvtr8-O"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Imprimir o resultado dos testes no Agente de IA\n",
        "for mensagem_teste in testes:\n",
        "  print(f\"Pergunta: {mensagem_teste}\\n -> Resposta: {triagem(mensagem_teste)}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DO5i4tgEtaKE",
        "outputId": "2edc54bf-f4b1-4856-a3a1-d7fe8b853614"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pergunta: Posso reembolsar a Internet?\n",
            " -> Resposta: {'decisao': 'AUTO_RESOLVER', 'urgencia': 'BAIXA', 'campos_faltantes': []}\n",
            "\n",
            "Pergunta: Quero mais 5 dias de trabalho remoto. Como faço?\n",
            " -> Resposta: {'decisao': 'ABRIR_CHAMADO', 'urgencia': 'MEDIA', 'campos_faltantes': []}\n",
            "\n",
            "Pergunta: Posso reembolsar cursos ou treinamentos?\n",
            " -> Resposta: {'decisao': 'AUTO_RESOLVER', 'urgencia': 'BAIXA', 'campos_faltantes': []}\n",
            "\n",
            "Pergunta: Quantas capivaras tem no Rio Pinheiros?\n",
            " -> Resposta: {'decisao': 'PEDIR_INFO', 'urgencia': 'BAIXA', 'campos_faltantes': ['assunto_politica']}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PALAVRA-CHAVE = LANGCHAIN**"
      ],
      "metadata": {
        "id": "V-KdVLu0uB3M"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JgdnmMTOuUna"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}